{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77914cb0",
   "metadata": {},
   "source": [
    "# Conversation Management & Classification using Groq API\n",
    "\n",
    "**Deliverables in this notebook:**\n",
    "\n",
    "- Task 1: Conversation history management with truncation and periodic summarization.\n",
    "- Task 2: JSON Schema classification & information extraction (name, email, phone, location, age).\n",
    "\n",
    "**Usage:** The notebook supports `MOCK_MODE=True` so you can run all demos offline. To run live with Groq, set `MOCK_MODE=False` and provide your `GROQ_API_KEY` through Colab environment variables or secrets (do NOT commit keys to GitHub).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3acfb0",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install lightweight dependencies and configure flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d27081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install --quiet jsonschema requests nbformat\n",
    "\n",
    "# Config\n",
    "MOCK_MODE = True   # Set to False to call Groq/OpenAI-compatible endpoints\n",
    "GROQ_API_KEY = ''  # Do NOT fill this in for public repos. Use environment vars in Colab.\n",
    "GROQ_BASE_URL = 'https://api.groq.com/openai/v1'  # OpenAI-compatible base path for Groq\n",
    "MODEL = 'openai/gpt-4o'  # Example model; change as per Groq docs\n",
    "\n",
    "import os\n",
    "if not GROQ_API_KEY:\n",
    "    GROQ_API_KEY = os.environ.get('GROQ_API_KEY', '')\n",
    "\n",
    "print('MOCK_MODE =', MOCK_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27cb956",
   "metadata": {},
   "source": [
    "## Task 1 — Conversation History Management with Summarization\n",
    "\n",
    "We keep `conversation_history` as a list of messages: `[{role:'user'|'assistant'|'system', 'content': '...'}]`.\n",
    "\n",
    "Features:\n",
    "- truncate by last n turns\n",
    "- truncate by char/word length\n",
    "- periodic summarization after every k-th run (configurable)\n",
    "\n",
    "A MOCK summarizer is included so the notebook runs without API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddeb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "def append_message(history: List[Dict], role: str, content: str):\n",
    "    history.append({'role': role, 'content': content})\n",
    "\n",
    "def truncate_by_turns(history: List[Dict], last_n_turns: int) -> List[Dict]:\n",
    "    # Keep last user+assistant pairs => approx last 2*last_n_turns messages\n",
    "    keep = max(0, last_n_turns * 2)\n",
    "    return history[-keep:] if keep and len(history) > keep else history.copy()\n",
    "\n",
    "def truncate_by_chars(history: List[Dict], max_chars: int) -> List[Dict]:\n",
    "    out = []\n",
    "    total = 0\n",
    "    for msg in reversed(history):\n",
    "        l = len(msg['content'])\n",
    "        if total + l > max_chars:\n",
    "            break\n",
    "        out.append(msg)\n",
    "        total += l\n",
    "    return list(reversed(out))\n",
    "\n",
    "def history_to_text(history: List[Dict]) -> str:\n",
    "    return '\\n'.join([f\"[{m['role']}] {m['content']}\" for m in history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "def mock_summarize(text: str, max_tokens: int = 120) -> str:\n",
    "    # Simple deterministic summary for offline demo\n",
    "    first = text.strip().split('\\n')[0][:200]\n",
    "    return f\"Summary: {first}... (orig_chars={len(text)})\"\n",
    "\n",
    "def groq_summarize(text: str, api_key: str, model: str='openai/gpt-4o', max_tokens: int = 200) -> str:\n",
    "    # Example OpenAI-compatible call to Groq's chat/completions endpoint.\n",
    "    # NOTE: This will work only when MOCK_MODE=False and a valid GROQ_API_KEY is provided.\n",
    "    url = f\"{GROQ_BASE_URL}/chat/completions\"\n",
    "    headers = {'Authorization': f'Bearer {api_key}', 'Content-Type': 'application/json'}\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'messages': [\n",
    "            {'role':'system', 'content':'You are a concise summarizer.'},\n",
    "            {'role':'user', 'content': f'Summarize the following conversation concisely:\\n\\n{text}'}\n",
    "        ],\n",
    "        'max_output_tokens': max_tokens\n",
    "    }\n",
    "    resp = requests.post(url, headers=headers, json=payload, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    # Try to extract content.\n",
    "    if isinstance(data, dict):\n",
    "        if 'choices' in data and len(data['choices'])>0 and 'message' in data['choices'][0]:\n",
    "            return data['choices'][0]['message'].get('content','').strip()\n",
    "        if 'output' in data and isinstance(data['output'], list):\n",
    "            parts = []\n",
    "            for o in data['output']:\n",
    "                if isinstance(o, dict) and 'content' in o:\n",
    "                    parts.append(o['content'])\n",
    "            return ' '.join(parts).strip()\n",
    "    return json.dumps(data)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72541cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    def __init__(self, mock_mode=True, api_key='', summarize_every_k=3, keep_tail=2):\n",
    "        self.history = []\n",
    "        self.run_count = 0\n",
    "        self.mock_mode = mock_mode\n",
    "        self.api_key = api_key\n",
    "        self.summarize_every_k = summarize_every_k\n",
    "        self.keep_tail = keep_tail  # number of recent messages to keep after summarization\n",
    "\n",
    "    def user_message(self, text: str):\n",
    "        append_message(self.history, 'user', text)\n",
    "        self.run_count += 1\n",
    "        if self.summarize_every_k>0 and self.run_count % self.summarize_every_k == 0:\n",
    "            self.perform_summarization()\n",
    "\n",
    "    def assistant_message(self, text: str):\n",
    "        append_message(self.history, 'assistant', text)\n",
    "\n",
    "    def perform_summarization(self):\n",
    "        full = history_to_text(self.history)\n",
    "        if self.mock_mode:\n",
    "            summary = mock_summarize(full)\n",
    "        else:\n",
    "            summary = groq_summarize(full, api_key=self.api_key)\n",
    "        tail = self.history[-self.keep_tail:] if len(self.history)>=self.keep_tail else self.history[:]\n",
    "        self.history = [{'role':'system','content': summary}] + tail\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "\n",
    "    def truncate(self, by_turns: Optional[int]=None, by_chars: Optional[int]=None):\n",
    "        h = self.history\n",
    "        if by_turns is not None:\n",
    "            h = truncate_by_turns(h, by_turns)\n",
    "        if by_chars is not None:\n",
    "            h = truncate_by_chars(h, by_chars)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d606538",
   "metadata": {},
   "source": [
    "### Demo: Task 1 — Periodic summarization & truncation\n",
    "\n",
    "We'll feed sample messages and show history after each run (summarization after k-th run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr = ConversationManager(mock_mode=MOCK_MODE, api_key=GROQ_API_KEY, summarize_every_k=3, keep_tail=2)\n",
    "samples = [\n",
    "    'Hi, I want to apply for the internship. My name is Rahul.',\n",
    "    'I live in Pune. My email is rahul@example.com.',\n",
    "    'My phone number is 9123456789 and I am 22 years old.',\n",
    "    'I can start from June.',\n",
    "    'I have experience with Python and HTML.',\n",
    "    'Please confirm interview schedule.'\n",
    "]\n",
    "for s in samples:\n",
    "    mgr.user_message(s)\n",
    "    mgr.assistant_message('Auto-reply (mock)')\n",
    "    print('\\n--- After run', mgr.run_count)\n",
    "    for m in mgr.get_history():\n",
    "        print(f\"[{m['role']}]\", m['content'][:200].replace('\\n',' '))\n",
    "    print('\\nTruncate by last 2 turns:') \n",
    "    print(history_to_text(mgr.truncate(by_turns=2)))\n",
    "    print('\\nTruncate by 150 chars:')\n",
    "    print(history_to_text(mgr.truncate(by_chars=150)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4331c4f",
   "metadata": {},
   "source": [
    "## Task 2 — JSON Schema Classification & Information Extraction\n",
    "\n",
    "We define a JSON schema to extract: name, email, phone, location, age. We'll show a heuristic extractor for MOCK mode and show how to call Groq/OpenAI function-calling style when MOCK_MODE=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3db961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema import validate, ValidationError\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
    "        \"phone\": {\"type\": \"string\"},\n",
    "        \"location\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"integer\"}\n",
    "    },\n",
    "    \"required\": [\"name\",\"email\",\"phone\",\"location\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "sample_chats = [\n",
    "    \"Hello, I'm Priya Singh. My email is priya.singh@mail.com and phone 9876543210. I'm from Bangalore and I'm 24.\",\n",
    "    \"Hey, this is Aman. Contact: aman1990@gmail.com, +91-9123456789. Mumbai-based.\",\n",
    "    \"Name: Kavita; Email: kk@example.com; Phone: 7012345678; Location: Jaipur; Age: 28.\"\n",
    "]\n",
    "\n",
    "import re\n",
    "def heuristic_extract(text: str) -> dict:\n",
    "    out = {}\n",
    "    # name heuristics\n",
    "    m = re.search(r\"(?:I\\'?m|I am|this is)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\", text)\n",
    "    if not m:\n",
    "        m = re.search(r\"Name:\\s*([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\", text)\n",
    "    if m: out['name'] = m.group(1).strip()\n",
    "    # email\n",
    "    me = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "    if me: out['email'] = me.group(0)\n",
    "    # phone\n",
    "    mp = re.search(r\"(\\+?\\d[\\d\\- ]{7,}\\d)\", text)\n",
    "    if mp: out['phone'] = re.sub(r\"[^0-9]\", \"\", mp.group(0))\n",
    "    # location\n",
    "    ml = re.search(r\"(from|based in|based|Mumbai|Bangalore|Jaipur|Location:|location:)\\s*([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\", text)\n",
    "    if ml: out['location'] = ml.group(2).strip()\n",
    "    # age\n",
    "    ma = re.search(r\"\\b(1\\d{1}|[2-9]\\d)\\b\", text)\n",
    "    if ma: out['age'] = int(ma.group(0))\n",
    "    return out\n",
    "\n",
    "def validate_output(obj: dict):\n",
    "    try:\n",
    "        validate(instance=obj, schema=schema)\n",
    "        return True, None\n",
    "    except ValidationError as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Demo parse\n",
    "for c in sample_chats:\n",
    "    print('\\nChat:', c)\n",
    "    if MOCK_MODE:\n",
    "        parsed = heuristic_extract(c)\n",
    "    else:\n",
    "        # Here demonstrate how you would call Groq/OpenAI function-calling style (not executed in MOCK)\n",
    "        parsed = heuristic_extract(c)\n",
    "    ok, err = validate_output(parsed)\n",
    "    print('Parsed:', parsed, 'Valid:', ok, 'Error:', err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4718117",
   "metadata": {},
   "source": [
    "### Example: Function-calling payload (template)\n",
    "\n",
    "This cell shows how you'd prepare a function-calling style request compatible with OpenAI/Groq. Replace with actual call when MOCK_MODE=False and GROQ_API_KEY set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e71111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_function_call_payload(chat_text: str):\n",
    "    # Example function schema (as would be sent in function-calling scenarios)\n",
    "    function_schema = {\n",
    "        \"name\": \"extract_contact_info\",\n",
    "        \"description\": \"Extract contact details from user chat\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\":\"string\"},\n",
    "                \"email\": {\"type\":\"string\"},\n",
    "                \"phone\": {\"type\":\"string\"},\n",
    "                \"location\": {\"type\":\"string\"},\n",
    "                \"age\": {\"type\":\"integer\"}\n",
    "            },\n",
    "            \"required\": [\"name\",\"email\",\"phone\",\"location\"]\n",
    "        }\n",
    "    }\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"You are a JSON extractor. Return valid JSON.\"},\n",
    "        {\"role\":\"user\",\"content\": chat_text}\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"functions\": [function_schema],\n",
    "        \"function_call\": {\"name\": \"extract_contact_info\"}\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "# Example usage\n",
    "print(build_function_call_payload('Hi, I am Rohit...'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa507c",
   "metadata": {},
   "source": [
    "## How to push to GitHub (recommended)\n",
    "\n",
    "1. Create a new repository on GitHub.\n",
    "2. In Colab, configure git user and use a Personal Access Token (PAT) to push. Example:\n",
    "\n",
    "```bash\n",
    "!git config --global user.email \"you@example.com\"\n",
    "!git config --global user.name \"Your Name\"\n",
    "!git init\n",
    "!git remote add origin https://github.com/yourusername/yourrepo.git\n",
    "!git add Conversation_Management_and_Classification.ipynb\n",
    "!git commit -m \"Add assignment notebook\"\n",
    "!git push https://<TOKEN>@github.com/yourusername/yourrepo.git main\n",
    "```\n",
    "\n",
    "Use GitHub Secrets / Colab environment variables for tokens. Do NOT push API keys.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cbf67",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "- Conversation_Management_and_Classification.ipynb\n",
    "- README.md (instructions included)\n",
    "\n",
    "The ZIP below contains the notebook and a README file."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
